{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Models Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WELFake_Dataset_processed.tsv', sep='\\t')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, temp_text, train_labels, temp_labels = train_test_split(\n",
    "  df['full_text_processed'],\n",
    "  df['label'],\n",
    "  random_state=2018,\n",
    "  test_size=0.4,\n",
    "  stratify=df['label']\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "  temp_text,\n",
    "  temp_labels,\n",
    "  random_state=2018,\n",
    "  test_size=0.5,\n",
    "  stratify=temp_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gensim Word2Vec initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from Training.utils import makeWords, train_evaluate_and_test_models, visualize_results\n",
    "\n",
    "mod = gensim.models.Word2Vec(sentences=makeWords(df['full_text_processed']), vector_size=EMBEDDING_DIM, window=5, min_count=1, workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lengths = train_texts.apply(lambda x: len(str(x).split()))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.hist(text_lengths, bins=50, color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Text Lengths\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Mean Length: {np.mean(text_lengths):.2f}\")\n",
    "print(f\"Median Length: {np.median(text_lengths):.2f}\")\n",
    "print(f\"90th Percentile: {np.percentile(text_lengths, 90):.2f}\")\n",
    "print(f\"Maximum Length: {np.max(text_lengths):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NewsDatasetLSTM import NewsDatasetLSTM\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "max_len = 623 \n",
    "# Instantiate datasets\n",
    "train_dataset = NewsDatasetLSTM(train_texts, train_labels, mod, max_len=max_len)\n",
    "val_dataset = NewsDatasetLSTM(val_texts, val_labels, mod, max_len=max_len)\n",
    "test_dataset = NewsDatasetLSTM(test_texts, test_labels, mod, max_len=max_len)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,drop_last=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_negatives = len(df[df['label'] == 0])\n",
    "num_positives = len(df[df['label'] == 1])\n",
    "class_counts = [num_negatives, num_positives]\n",
    "\n",
    "results = train_evaluate_and_test_models(class_counts,train_loader, val_loader, test_loader, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
